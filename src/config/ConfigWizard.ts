import inquirer from 'inquirer';
import chalk from 'chalk';
import axios from 'axios';
import { AIConfig, AppConfig } from '../types/config';
import { ConfigManager } from './ConfigManager';

export class ConfigWizard {
  private configManager: ConfigManager;

  constructor() {
    this.configManager = new ConfigManager();
  }

  async runSetup(): Promise<AppConfig> {
    console.log(chalk.blue.bold('\nğŸ”§ æ¬¢è¿ä½¿ç”¨æ—¥å¿—åˆ†æå·¥å…·é…ç½®å‘å¯¼\n'));
    
    const existingConfig = await this.configManager.loadConfig();
    
    if (existingConfig) {
      const { shouldUpdate } = await inquirer.prompt([
        {
          type: 'confirm',
          name: 'shouldUpdate',
          message: 'æ£€æµ‹åˆ°ç°æœ‰é…ç½®ï¼Œæ˜¯å¦è¦æ›´æ–°ï¼Ÿ',
          default: false
        }
      ]);

      if (!shouldUpdate) {
        return existingConfig;
      }
    }

    const aiConfig = await this.configureAI(existingConfig?.ai);
    
    const newConfig: AppConfig = {
      ai: aiConfig,
      version: '1.0.0',
      lastUpdated: new Date().toISOString()
    };

    await this.testConnection(aiConfig);
    await this.configManager.saveConfig(newConfig);
    
    console.log(chalk.green('\nâœ… é…ç½®ä¿å­˜æˆåŠŸï¼'));
    console.log(chalk.gray(`é…ç½®æ–‡ä»¶ä½ç½®: ${this.configManager.getConfigPath()}`));
    
    return newConfig;
  }

  private async configureAI(existingAI?: AIConfig): Promise<AIConfig> {
    console.log(chalk.yellow('\nğŸ“¡ é…ç½®AIæœåŠ¡æä¾›å•†'));

    const { provider } = await inquirer.prompt([
      {
        type: 'list',
        name: 'provider',
        message: 'é€‰æ‹©AIæœåŠ¡æä¾›å•†:',
        choices: [
          { name: 'OpenAI (ChatGPT)', value: 'openai' },
          { name: 'Anthropic (Claude)', value: 'anthropic' },
          { name: 'Ollama (æœ¬åœ°æ¨¡å‹)', value: 'ollama' },
          { name: 'è‡ªå®šä¹‰API', value: 'custom' }
        ],
        default: existingAI?.provider || 'openai'
      }
    ]);

    let defaultUrl: string;
    let defaultModel: string;

    switch (provider) {
      case 'openai':
        defaultUrl = 'https://api.openai.com/v1';
        defaultModel = 'gpt-3.5-turbo';
        break;
      case 'anthropic':
        defaultUrl = 'https://api.anthropic.com';
        defaultModel = 'claude-3-haiku-20240307';
        break;
      case 'ollama':
        defaultUrl = 'http://localhost:11434/v1';
        defaultModel = 'llama3.2:latest';
        break;
      default:
        defaultUrl = existingAI?.apiUrl || 'https://api.example.com/v1';
        defaultModel = existingAI?.modelId || 'your-model';
    }

    const answers = await inquirer.prompt([
      {
        type: 'input',
        name: 'apiUrl',
        message: 'APIåœ°å€:',
        default: existingAI?.apiUrl || defaultUrl,
        validate: (input: string) => {
          try {
            new URL(input);
            return true;
          } catch {
            return 'è¯·è¾“å…¥æœ‰æ•ˆçš„URL';
          }
        }
      },
      {
        type: 'password',
        name: 'apiKey',
        message: provider === 'ollama' ? 'APIå¯†é’¥ (ollamaé€šå¸¸ä¸éœ€è¦ï¼Œå¯ç•™ç©º):' : 'APIå¯†é’¥:',
        mask: '*',
        validate: (input: string) => {
          if (provider === 'ollama') {
            return true; // ollamaä¸éœ€è¦APIå¯†é’¥
          }
          if (!input || input.trim() === '') {
            return 'APIå¯†é’¥ä¸èƒ½ä¸ºç©º';
          }
          return true;
        }
      },
      {
        type: 'input',
        name: 'modelId',
        message: 'æ¨¡å‹ID:',
        default: existingAI?.modelId || defaultModel
      },
      {
        type: 'number',
        name: 'maxTokens',
        message: 'æœ€å¤§Tokenæ•° (å¯é€‰):',
        default: existingAI?.maxTokens || 4000
      },
      {
        type: 'number',
        name: 'temperature',
        message: 'æ¸©åº¦å‚æ•° (0-2, å¯é€‰):',
        default: existingAI?.temperature || 0.7,
        validate: (input: string) => {
          const num = parseFloat(input);
          if (isNaN(num) || num < 0 || num > 2) {
            return 'æ¸©åº¦å‚æ•°å¿…é¡»åœ¨0-2ä¹‹é—´';
          }
          return true;
        }
      }
    ]);

    return {
      provider,
      ...answers
    };
  }

  private async testConnection(aiConfig: AIConfig): Promise<void> {
    console.log(chalk.yellow('\nğŸ” æµ‹è¯•APIè¿æ¥...'));

    try {
      let testRequest;

      if (aiConfig.provider === 'openai') {
        testRequest = axios.post(
          `${aiConfig.apiUrl}/chat/completions`,
          {
            model: aiConfig.modelId,
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
          },
          {
            headers: {
              'Authorization': `Bearer ${aiConfig.apiKey}`,
              'Content-Type': 'application/json'
            },
            timeout: 10000
          }
        );
      } else if (aiConfig.provider === 'anthropic') {
        testRequest = axios.post(
          `${aiConfig.apiUrl}/v1/messages`,
          {
            model: aiConfig.modelId,
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
          },
          {
            headers: {
              'x-api-key': aiConfig.apiKey,
              'Content-Type': 'application/json',
              'anthropic-version': '2023-06-01'
            },
            timeout: 10000
          }
        );
      } else if (aiConfig.provider === 'ollama') {
        // æµ‹è¯•ollamaçš„/api/tagsç«¯ç‚¹
        testRequest = axios.get(
          `${aiConfig.apiUrl}/api/tags`,
          {
            headers: {
              'Content-Type': 'application/json'
            },
            timeout: 10000
          }
        );
      } else {
        console.log(chalk.yellow('âš ï¸  è‡ªå®šä¹‰APIï¼Œè·³è¿‡è¿æ¥æµ‹è¯•'));
        return;
      }

      await testRequest;
      console.log(chalk.green('âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸï¼'));
      
    } catch (error: any) {
      if (error.response) {
        if (error.response.status === 401) {
          throw new Error('APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®');
        } else if (error.response.status === 403) {
          throw new Error('APIè®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥è´¦æˆ·æƒé™');
        } else {
          console.log(chalk.yellow(`âš ï¸  APIè¿æ¥æµ‹è¯•è¿”å›çŠ¶æ€ç : ${error.response.status}`));
          console.log(chalk.yellow('é…ç½®å·²ä¿å­˜ï¼Œè¯·ç¡®ä¿APIæœåŠ¡æ­£å¸¸'));
        }
      } else if (error.code === 'ENOTFOUND' || error.code === 'ECONNREFUSED') {
        throw new Error('æ— æ³•è¿æ¥åˆ°APIæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIåœ°å€');
      } else {
        console.log(chalk.yellow('âš ï¸  APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œä½†é…ç½®å·²ä¿å­˜'));
        console.log(chalk.gray(`é”™è¯¯: ${error.message}`));
      }
    }
  }

  async showCurrentConfig(): Promise<void> {
    const config = await this.configManager.loadConfig();
    
    if (!config) {
      console.log(chalk.yellow('âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶'));
      return;
    }

    console.log(chalk.blue.bold('\nğŸ“‹ å½“å‰é…ç½®ä¿¡æ¯:'));
    console.log(chalk.gray('â”€'.repeat(40)));
    console.log(`${chalk.cyan('æä¾›å•†:')} ${config.ai.provider}`);
    console.log(`${chalk.cyan('APIåœ°å€:')} ${config.ai.apiUrl}`);
    console.log(`${chalk.cyan('æ¨¡å‹ID:')} ${config.ai.modelId}`);
    console.log(`${chalk.cyan('APIå¯†é’¥:')} ${'*'.repeat(8)}${config.ai.apiKey.slice(-4)}`);
    console.log(`${chalk.cyan('æœ€å¤§Token:')} ${config.ai.maxTokens || 'æœªè®¾ç½®'}`);
    console.log(`${chalk.cyan('æ¸©åº¦å‚æ•°:')} ${config.ai.temperature || 'æœªè®¾ç½®'}`);
    console.log(`${chalk.cyan('æœ€åæ›´æ–°:')} ${new Date(config.lastUpdated).toLocaleString()}`);
    console.log(chalk.gray('â”€'.repeat(40)));
  }

  async resetConfig(): Promise<void> {
    const { confirm } = await inquirer.prompt([
      {
        type: 'confirm',
        name: 'confirm',
        message: 'ç¡®å®šè¦é‡ç½®æ‰€æœ‰é…ç½®å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚',
        default: false
      }
    ]);

    if (confirm) {
      await this.configManager.resetConfig();
      console.log(chalk.green('âœ… é…ç½®å·²é‡ç½®'));
    } else {
      console.log(chalk.yellow('å·²å–æ¶ˆé‡ç½®æ“ä½œ'));
    }
  }
}